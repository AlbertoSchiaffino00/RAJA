<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Vectorization (SIMD/SIMT) &mdash; RAJA 2022.03.1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Plugins" href="plugins.html" />
    <link rel="prev" title="WorkGroup" href="workgroup.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> RAJA
            <img src="../../../_static/RAJA_LOGO_CMYK_White_Background_large.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2022.03
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Documentation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">RAJA User Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../getting_started.html">Getting Started With RAJA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../using_raja.html">Using RAJA in Your Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../config_options.html">Build Configuration Options</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../features.html">RAJA Features</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="loop_basic.html">Elements of Loop Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="policies.html">Policies</a></li>
<li class="toctree-l3"><a class="reference internal" href="iteration_spaces.html">Indices, Segments, and IndexSets</a></li>
<li class="toctree-l3"><a class="reference internal" href="view.html">View and Layout</a></li>
<li class="toctree-l3"><a class="reference internal" href="reduction.html">Reduction Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="atomic.html">Atomic Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="scan.html">Scan Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="sort.html">Sort Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="resource.html">Resources</a></li>
<li class="toctree-l3"><a class="reference internal" href="local_array.html">Local Array</a></li>
<li class="toctree-l3"><a class="reference internal" href="tiling.html">Loop Tiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="workgroup.html">WorkGroup</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Vectorization (SIMD/SIMT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#why-are-we-doing-this">Why Are We Doing This?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#register">Register</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vector-register">Vector Register</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-register">Tensor Register</a></li>
<li class="toctree-l4"><a class="reference internal" href="#matrix-registers">Matrix Registers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plugins.html">Plugins</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../app_considerations.html">Application Considerations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial.html">RAJA Tutorial and Examples</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev_guide/index.html">RAJA Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../raja_license.html">RAJA Copyright and License Information</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">RAJA</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">RAJA User Guide</a> &raquo;</li>
          <li><a href="../features.html">RAJA Features</a> &raquo;</li>
      <li>Vectorization (SIMD/SIMT)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/sphinx/user_guide/feature/vectorization.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="vectorization-simd-simt">
<span id="vectorization-label"></span><h1>Vectorization (SIMD/SIMT)<a class="headerlink" href="#vectorization-simd-simt" title="Permalink to this headline">¶</a></h1>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><strong>This section describes an initial draft of an incomplete,
experimental RAJA capability. It is not considered ready
for production, but it is ready for interested users to try.</strong></p>
<ul class="simple">
<li><p>We provide a basic description here so that interested users
can take a look, try it out, and provide input if they wish to
do so. The RAJA team values early feedback from users on new
capabilities.</p></li>
<li><p>There are no usage examples available in RAJA yet, except for
tests. Examples will be made available as they are developed.</p></li>
</ul>
</div>
<p>The aim of the RAJA API for SIMD/SIMT programming described in this section
is to make an implementation perform as well as if one used
SIMD/SIMT intrinsics directly in her code, but without the
software complexity and maintenance burden associated with doing that.
In particular, we want to <em>guarantee</em> that specified vectorization
occurs without requiring users to manually insert intrinsics in their code or
rely on compiler auto-vectorization implementations.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All RAJA vectorization types described here are in the namespace
<code class="docutils literal notranslate"><span class="pre">RAJA::expt</span></code>.</p>
</div>
<p>Currently, the main abstractions in RAJA for SIMD/SIMT programming are:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Register</span></code> which wraps underlying SIMD/SIMT hardware registers and
provides consistent uniform access to them, using intrinsics behind the
API when possible. The register abstraction currently supports the
following hardware-specific ISAs (instruction set architectures):
AVX, AVX2, AVX512, CUDA, and HIP.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Vector</span></code> which builds on <code class="docutils literal notranslate"><span class="pre">Register</span></code> to provide arbitrary length
vectors and operations on them.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Matrix</span></code> which builds on <code class="docutils literal notranslate"><span class="pre">Register</span></code> to provide arbitrary-sized
matrices and operations on them, including support for column-major and
row-major data layouts.</p></li>
</ul>
</div></blockquote>
<p>Using these abstractions, RAJA provides an expression-template system that
allows users to write linear algebra expressions on arbitrarily sized scalars,
vectors, and matrices and have the appropriate SIMD/SIMT instructions
performed during expression evaluation. These capabilities integrate with
RAJA <a class="reference internal" href="view.html#feat-view-label"><span class="std std-ref">View and Layout</span></a> capabilities, which insulate load/store and other
operations from user code.</p>
<section id="why-are-we-doing-this">
<h2>Why Are We Doing This?<a class="headerlink" href="#why-are-we-doing-this" title="Permalink to this headline">¶</a></h2>
<p>Quoting Tim Foley in <a class="reference external" href="https://pharr.org/matt/blog/2018/04/18/ispc-origins">Matt Pharr’s blog</a> – “Auto-vectorization is not a programming model”. This is
true, of course, unless you consider “hope for the best” that the compiler
optimizes the way you want to be a sound code development strategy.</p>
<p>Compiler auto-vectorization is problematic for multiple reasons. First, when
vectorization is not explicit in source code, compilers must divine correctness
when attempting to apply vectorization optimizations. Most compilers are very
conservative in this regard, due to the possibility of data aliasing in C and
C++ and prioritizing correctness over performance. Thus, many vectorization
opportunities are usually missed when one relies solely on compiler
auto-vectorization.  Second, every compiler will treat your code differently
since compiler implementations use different optimization heuristics, even in
different versions of the same compiler. So performance portability is not
just an issue with respect to hardware, but also for compilers. Third, it is
generally impossible for most application developers to clearly understand
the choices made by compilers during optimization processes.</p>
<p>Using vectorization intrinsics in application source code is also problematic
because different processors support different instruction set architectures
(ISAs) and so source code portability requires a mechanism that insulates it
from architecture-specific code.</p>
<p>Writing GPU code makes a programmer be explicit about parallelization, and SIMD
is really no different. RAJA enables single-source portable code across a
variety of programming model back-ends. The RAJA vectorization abstractions
introduced here are an attempt to bring some convergence between SIMD
and GPU programming by providing uniform access to hardware-specific
acceleration.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p><strong>Auto-vectorization is not a programming model.</strong> –Tim Foley</p>
</div>
</section>
<section id="register">
<h2>Register<a class="headerlink" href="#register" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register&lt;T,</span> <span class="pre">REGISTER_POLICY&gt;</span></code> is a class template with
parameters for a data type <code class="docutils literal notranslate"><span class="pre">T</span></code> and a register policy <code class="docutils literal notranslate"><span class="pre">REGISTER_POLICY</span></code>,
which specifies the hardware register type. It is intended as a building block
for higher level abstractions.  The <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code> interface provides
uniform access to register-level operations for different hardware features
and ISA models. A <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code> type represents one SIMD register
on a CPU architecture and 1 value/SIMT lane on a GPU architecture.</p>
<p><code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code> supports four scalar element types, <code class="docutils literal notranslate"><span class="pre">int32_t</span></code>,
<code class="docutils literal notranslate"><span class="pre">int64_t</span></code>, <code class="docutils literal notranslate"><span class="pre">float</span></code>, and <code class="docutils literal notranslate"><span class="pre">double</span></code>. These are the only types that are
portable across all SIMD/SIMT architectures. <code class="docutils literal notranslate"><span class="pre">Bfloat</span></code>, for example, is not
portable, so we don’t provide support for that type.</p>
<p><code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code> supports the following SIMD/SIMT hardware-specific
ISAs: AVX, AVX2, and AVX512 for SIMD CPU vectorization, and CUDA warp and
HIP wavefront for NVIDIA and AMD GPUs, respectively. Scalar support is
provided for all hardware for portability and experimentation/analysis.
Extensions to support other architectures may be forthcoming as they are
needed and requested by users.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>One can use the <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code> type directly in her
code. However, we do not recommend it. Instead, we want users to
employ higher level abstractions that RAJA provides.</p>
</div>
<section id="register-operations">
<h3>Register Operations<a class="headerlink" href="#register-operations" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code> provides various operations which include:</p>
<blockquote>
<div><ul class="simple">
<li><p>Basic SIMD handling: get element, broadcast</p></li>
<li><p>Memory operations: load (packed, strided, gather) and store (packed, strided, scatter)</p></li>
<li><p>SIMD element-wise arithmetic: add, subtract, multiply, divide, vmin, vmax</p></li>
<li><p>Reductions: dot-product, sum, min, max</p></li>
<li><p>Special operations for matrix operations: permutations, segmented operations</p></li>
</ul>
</div></blockquote>
</section>
<section id="register-daxpy-example">
<h3>Register DAXPY Example<a class="headerlink" href="#register-daxpy-example" title="Permalink to this headline">¶</a></h3>
<p>The following code example shows how to use the <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code>
class to perform a DAXPY kernel with AVX2 SIMD instructions.
While we do not recommend that you write code directly using the Register
class, but instead use the higher level VectorRegister abstraction, we use
the Register type here to illustrate the basics mechanics of SIMD
vectorization:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Define</span> <span class="n">array</span> <span class="n">length</span>
<span class="nb">int</span> <span class="nb">len</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>

<span class="o">//</span> <span class="n">Define</span> <span class="n">data</span> <span class="n">used</span> <span class="ow">in</span> <span class="n">kernel</span>
<span class="n">double</span> <span class="n">a</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="n">const</span> <span class="o">*</span><span class="n">X</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="n">const</span> <span class="o">*</span><span class="n">Y</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="o">*</span><span class="n">Z</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>

<span class="o">//</span> <span class="n">Define</span> <span class="n">an</span> <span class="n">avx2</span> <span class="n">register</span><span class="p">,</span> <span class="n">which</span> <span class="n">has</span> <span class="n">width</span> <span class="n">of</span> <span class="mi">4</span> <span class="n">doubles</span>
<span class="n">using</span> <span class="n">reg_t</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">Register</span><span class="o">&lt;</span><span class="n">double</span><span class="p">,</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">avx2_register</span><span class="o">&gt;</span><span class="p">;</span>
<span class="nb">int</span> <span class="n">reg_width</span> <span class="o">=</span> <span class="n">reg_t</span><span class="p">::</span><span class="n">s_num_elem</span><span class="p">;</span>

<span class="o">//</span> <span class="n">Compute</span> <span class="n">daxpy</span> <span class="ow">in</span> <span class="n">chunks</span> <span class="n">of</span> <span class="mi">4</span> <span class="n">values</span> <span class="p">(</span><span class="n">register</span> <span class="n">width</span><span class="p">)</span> <span class="n">at</span> <span class="n">a</span> <span class="n">time</span>
<span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span><span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="n">reg_width</span><span class="p">){</span>
  <span class="n">reg_t</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">;</span>

  <span class="o">//</span> <span class="n">Load</span> <span class="mi">4</span> <span class="n">consecutive</span> <span class="n">values</span> <span class="n">of</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="n">arrays</span> <span class="n">into</span> <span class="n">registers</span>
  <span class="n">x</span><span class="o">.</span><span class="n">load_packed</span><span class="p">(</span> <span class="n">X</span><span class="o">+</span><span class="n">i</span> <span class="p">);</span>
  <span class="n">y</span><span class="o">.</span><span class="n">load_packed</span><span class="p">(</span> <span class="n">Y</span><span class="o">+</span><span class="n">i</span> <span class="p">);</span>

  <span class="o">//</span> <span class="n">Perform</span> <span class="n">daxpy</span> <span class="n">on</span> <span class="mi">4</span> <span class="n">values</span> <span class="n">simultaneously</span> <span class="ow">and</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">register</span>
  <span class="n">reg_t</span> <span class="n">z</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">;</span>

  <span class="o">//</span> <span class="n">Store</span> <span class="n">register</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">Z</span> <span class="n">array</span>
  <span class="n">z</span><span class="o">.</span><span class="n">store_packed</span><span class="p">(</span> <span class="n">Z</span><span class="o">+</span><span class="n">i</span> <span class="p">);</span>
<span class="p">}</span>

<span class="o">//</span> <span class="n">Loop</span> <span class="n">postamble</span> <span class="n">code</span> <span class="n">to</span> <span class="n">complete</span> <span class="n">daxpy</span> <span class="n">operation</span> <span class="n">when</span> <span class="n">array</span> <span class="n">length</span>
<span class="o">//</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">an</span> <span class="n">integer</span> <span class="n">multiple</span> <span class="n">of</span> <span class="n">the</span> <span class="n">register</span> <span class="n">width</span>
<span class="nb">int</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">len</span> <span class="o">%</span> <span class="n">reg_width</span><span class="p">;</span>
<span class="k">if</span> <span class="p">(</span><span class="n">remainder</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">reg_t</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">;</span>

  <span class="o">//</span> <span class="s1">&#39;i&#39;</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">starting</span> <span class="n">array</span> <span class="n">index</span> <span class="n">of</span> <span class="n">the</span> <span class="n">remainder</span>
  <span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="nb">len</span> <span class="o">-</span> <span class="n">remainder</span><span class="p">;</span>

  <span class="o">//</span> <span class="n">Load</span> <span class="n">remainder</span> <span class="n">values</span> <span class="n">of</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="n">arrays</span> <span class="n">into</span> <span class="n">registers</span>
  <span class="n">x</span><span class="o">.</span><span class="n">load_packed_n</span><span class="p">(</span> <span class="n">X</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">remainder</span> <span class="p">);</span>
  <span class="n">y</span><span class="o">.</span><span class="n">load_packed_n</span><span class="p">(</span> <span class="n">Y</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">remainder</span> <span class="p">);</span>

  <span class="o">//</span> <span class="n">Perform</span> <span class="n">daxpy</span> <span class="n">on</span> <span class="n">remainder</span> <span class="n">values</span> <span class="n">simultaneously</span> <span class="ow">and</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">register</span>
  <span class="n">reg_t</span> <span class="n">z</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">;</span>

  <span class="o">//</span> <span class="n">Store</span> <span class="n">register</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">Z</span> <span class="n">array</span>
  <span class="n">z</span><span class="o">.</span><span class="n">store_packed_n</span><span class="p">(</span><span class="n">Z</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">remainder</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This code is guaranteed to vectorize since the <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code>
operations insert the appropriate SIMD intrinsics into the operation
calls. Since <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code> provides overloads of basic
arithmetic operations, the SIMD DAXPY operation <code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">=</span> <span class="pre">a</span> <span class="pre">*</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code> looks
like vanilla scalar code.</p>
<p>Because we are using bare pointers to the data, load and store
operations are performed by explicit method calls in the code. Also, we must
write explicit <em>postamble</em> code to handle cases where the array length
<code class="docutils literal notranslate"><span class="pre">len</span></code> is not an integer multiple of the register width <code class="docutils literal notranslate"><span class="pre">reg_width</span></code>. The
postamble code performs the DAXPY operation on the <em>remainder</em> of the array
that is excluded from the for-loop, which is strided by the register width.</p>
<p><strong>The need to write extra postamble code should make clear one reason why we
do not recommend using ``RAJA::Register`` directly in application code.</strong></p>
</section>
</section>
<section id="vector-register">
<h2>Vector Register<a class="headerlink" href="#vector-register" title="Permalink to this headline">¶</a></h2>
<p><strong>To make code cleaner and more readable, the specific types are intended to
be used with ``RAJA::View`` and ``RAJA::expt::TensorIndex`` objects.</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">RAJA::expt::VectorRegister&lt;T,</span> <span class="pre">REGISTER_POLICY,</span> <span class="pre">NUM_ELEM&gt;</span></code> provides an
abstraction for a vector of arbitrary length. It is implemented using one or
more <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code> objects. The vector length is independent of the
underlying register width. The template parameters are: data type <code class="docutils literal notranslate"><span class="pre">T</span></code>,
vector register policy <code class="docutils literal notranslate"><span class="pre">REGISTER_POLICY</span></code>, and <code class="docutils literal notranslate"><span class="pre">NUM_ELEM</span></code> which
is the number of data elements of type <code class="docutils literal notranslate"><span class="pre">T</span></code> that fit in a register. The last
two of these template parameters have defaults for all cases, so a user
need note provide them in most cases.</p>
<p>Recall that we said earlier that we do not recommended using
<code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code> directly. One important reason for this is that
decoupling the vector length from hardware register size allows one to write
simpler, more readable code that is easier to get correct. This should be
clear from the code example below, when compared to the previous code example.</p>
<section id="vector-register-daxpy-example">
<h3>Vector Register DAXPY Example<a class="headerlink" href="#vector-register-daxpy-example" title="Permalink to this headline">¶</a></h3>
<p>The following code example shows the DAXPY computation discussed above,
but written using <code class="docutils literal notranslate"><span class="pre">RAJA::expt::VectorRegister</span></code>, <code class="docutils literal notranslate"><span class="pre">RAJA::expt::VectorIndex</span></code>,
and <code class="docutils literal notranslate"><span class="pre">RAJA::View</span></code> types. Using these types, we can write cleaner, more
concise code that is easier to get correct because it is simpler. For example,
we do not have to write the postamble code discussed earlier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Define</span> <span class="n">array</span> <span class="n">length</span> <span class="ow">and</span> <span class="n">data</span> <span class="n">used</span> <span class="ow">in</span> <span class="n">kernel</span> <span class="p">(</span><span class="k">as</span> <span class="n">before</span><span class="p">)</span>
<span class="nb">int</span> <span class="nb">len</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="n">a</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="n">const</span> <span class="o">*</span><span class="n">X</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="n">const</span> <span class="o">*</span><span class="n">Y</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="o">*</span><span class="n">Z</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>

<span class="o">//</span> <span class="n">Define</span> <span class="n">vector</span> <span class="n">register</span> <span class="ow">and</span> <span class="n">index</span> <span class="n">types</span>
<span class="n">using</span> <span class="n">vec_t</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">VectorRegister</span><span class="o">&lt;</span><span class="n">double</span><span class="p">,</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">avx2_register</span><span class="o">&gt;</span><span class="p">;</span>
<span class="n">using</span> <span class="n">idx_t</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">VectorIndex</span><span class="o">&lt;</span><span class="nb">int</span><span class="p">,</span> <span class="n">vec_t</span><span class="o">&gt;</span><span class="p">;</span>

<span class="o">//</span> <span class="n">Wrap</span> <span class="n">array</span> <span class="n">pointers</span> <span class="ow">in</span> <span class="n">RAJA</span> <span class="n">View</span> <span class="n">objects</span>
<span class="n">auto</span> <span class="n">vX</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">make_view</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span> <span class="nb">len</span> <span class="p">);</span>
<span class="n">auto</span> <span class="n">vY</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">make_view</span><span class="p">(</span> <span class="n">Y</span><span class="p">,</span> <span class="nb">len</span> <span class="p">);</span>
<span class="n">auto</span> <span class="n">vZ</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">make_view</span><span class="p">(</span> <span class="n">Z</span><span class="p">,</span> <span class="nb">len</span> <span class="p">);</span>

<span class="o">//</span> <span class="n">The</span> <span class="s1">&#39;all&#39;</span> <span class="n">variable</span> <span class="n">gets</span> <span class="n">the</span> <span class="n">length</span> <span class="n">of</span> <span class="n">the</span> <span class="n">arrays</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">vX</span><span class="p">,</span> <span class="n">vY</span><span class="p">,</span> <span class="ow">and</span>
<span class="o">//</span> <span class="n">vZ</span> <span class="n">View</span> <span class="n">objects</span> <span class="ow">and</span> <span class="n">encodes</span> <span class="n">the</span> <span class="n">vector</span> <span class="n">register</span> <span class="nb">type</span>
<span class="n">auto</span> <span class="nb">all</span> <span class="o">=</span> <span class="n">idx_t</span><span class="p">::</span><span class="nb">all</span><span class="p">();</span>

<span class="o">//</span> <span class="n">Compute</span> <span class="n">the</span> <span class="n">complete</span> <span class="n">array</span> <span class="n">daxpy</span> <span class="ow">in</span> <span class="n">one</span> <span class="n">line</span> <span class="n">of</span> <span class="n">code</span>
<span class="o">//</span> <span class="n">this</span> <span class="n">produces</span> <span class="n">a</span> <span class="n">vectorized</span> <span class="n">loop</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">loop</span> <span class="n">postamble</span>
<span class="o">//</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">executable</span>
<span class="n">vZ</span><span class="p">(</span> <span class="nb">all</span> <span class="p">)</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">vX</span><span class="p">(</span> <span class="nb">all</span> <span class="p">)</span> <span class="o">+</span> <span class="n">vY</span><span class="p">(</span> <span class="nb">all</span> <span class="p">);</span>
</pre></div>
</div>
<p>It should be clear that this code has several advantages over the previous
code example. It is guaranteed to vectorize as before, but it is much easier
to read, get correct, and maintain since the <code class="docutils literal notranslate"><span class="pre">RAJA::View</span></code> class handles the
looping and postamble code automatically for arrays of arbitrary size. The
<code class="docutils literal notranslate"><span class="pre">RAJA::View</span></code> class provides overloads of the arithmetic operations based on
the <code class="docutils literal notranslate"><span class="pre">all</span></code> variable and inserts the appropriate SIMD instructions and
load/store operations to vectorize the operations that were explicit in the
earlier example. It may be considered by some to be inconvenient to have to
use the <code class="docutils literal notranslate"><span class="pre">RAJA::View</span></code> class, but it is easy to wrap bare pointers as is shown
here.</p>
</section>
<section id="expression-templates">
<h3>Expression Templates<a class="headerlink" href="#expression-templates" title="Permalink to this headline">¶</a></h3>
<p>The figure below shows the sequence of SIMD operations, as they are parsed to
form of an <em>abstract syntax tree (AST)</em>, for the DAXPY code in the vector
register code example above.</p>
<figure class="align-default" id="id1">
<img alt="../../../_images/vectorET.png" src="../../../_images/vectorET.png" />
<figcaption>
<p><span class="caption-text">An AST illustration of the SIMD operations in the DAXPY code.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>During compilation, a tree of <em>expression template</em> objects is constructed
based on the order of operations that appear in the DAXPY kernel. Specifically,
the operation sequence is the following:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Load a chunk of values in ‘vX’ into a register.</p></li>
<li><p>Broadcast the scalar value ‘a’ to each slot in a vector register.</p></li>
<li><p>Load a chunk of values in ‘vY’ into a register.</p></li>
<li><p>Multiply values in the ‘a’ register and ‘vX’ register and multiply
by the values in the ‘vY’ register in a single vector FMA
(Fused Multiply-Add) operation, storing the result in a register.</p></li>
<li><p>Write the result in the register to the ‘vZ’ array.</p></li>
</ol>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">RAJA::View</span></code> objects indexed by <code class="docutils literal notranslate"><span class="pre">RAJA::TensorIndex</span></code> objects
(<code class="docutils literal notranslate"><span class="pre">RAJA::VectorIndex</span></code> in this case) return <em>Load/Store</em> expression
template objects. Each expression template object is evaluated on assignment
and a register chunk size of values is loaded into another register object.
Finally, the left-hand side of the expression is evaluated by storing the
chunk of values in the right-hand side result register into the array associated
with the view <code class="docutils literal notranslate"><span class="pre">vZ</span></code> on the left-hand side of the equal sign.</p>
</section>
<section id="cpu-gpu-portability">
<h3>CPU/GPU Portability<a class="headerlink" href="#cpu-gpu-portability" title="Permalink to this headline">¶</a></h3>
<p>It is important to note that the code in the example above can only run on a
CPU; i.e., it is <em>not</em> portable to run on either a CPU or GPU because it does
not include a way to launch a GPU kernel. The following code example shows
how to enable the code to run on either a CPU or GPU via a run time choice:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">array</span> <span class="n">lengths</span> <span class="ow">and</span> <span class="n">data</span> <span class="n">used</span> <span class="ow">in</span> <span class="n">kernel</span> <span class="n">same</span> <span class="k">as</span> <span class="n">above</span>

<span class="o">//</span> <span class="n">define</span> <span class="n">vector</span> <span class="n">register</span> <span class="ow">and</span> <span class="n">index</span> <span class="n">types</span>
<span class="n">using</span> <span class="n">vec_t</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">VectorRegister</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">;</span>
<span class="n">using</span> <span class="n">idx_t</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">VectorIndex</span><span class="o">&lt;</span><span class="nb">int</span><span class="p">,</span> <span class="n">vec_t</span><span class="o">&gt;</span><span class="p">;</span>

<span class="o">//</span> <span class="n">array</span> <span class="n">pointers</span> <span class="n">wrapped</span> <span class="ow">in</span> <span class="n">RAJA</span> <span class="n">View</span> <span class="n">objects</span> <span class="k">as</span> <span class="n">before</span>
<span class="o">//</span> <span class="o">...</span>

<span class="n">using</span> <span class="n">cpu_launch</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">seq_launch_t</span><span class="p">;</span>
<span class="n">using</span> <span class="n">gpu_launch</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">cuda_launch_t</span><span class="o">&lt;</span><span class="n">false</span><span class="o">&gt;</span><span class="p">;</span> <span class="o">//</span> <span class="n">false</span> <span class="o">=&gt;</span> <span class="n">launch</span>
                                                     <span class="o">//</span> <span class="n">CUDA</span> <span class="n">kernel</span>
                                                     <span class="o">//</span> <span class="n">synchronously</span>

<span class="n">using</span> <span class="n">pol_t</span> <span class="o">=</span>
  <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">LoopPolicy</span><span class="o">&lt;</span> <span class="n">cpu_launch</span><span class="p">,</span> <span class="n">gpu_launch</span> <span class="o">&gt;</span><span class="p">;</span>

<span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">ExecPlace</span> <span class="n">cpu_or_gpu</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>

<span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">launch</span><span class="o">&lt;</span><span class="n">pol_t</span><span class="o">&gt;</span><span class="p">(</span> <span class="n">cpu_or_gpu</span><span class="p">,</span> <span class="n">resources</span><span class="p">,</span>

                           <span class="p">[</span><span class="o">=</span><span class="p">]</span> <span class="n">RAJA_HOST_DEVICE</span> <span class="p">(</span><span class="n">context</span> <span class="n">ctx</span><span class="p">)</span> <span class="p">{</span>
                               <span class="n">auto</span> <span class="nb">all</span> <span class="o">=</span> <span class="n">idx_t</span><span class="p">::</span><span class="nb">all</span><span class="p">();</span>
                               <span class="n">vZ</span><span class="p">(</span> <span class="nb">all</span> <span class="p">)</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">vX</span><span class="p">(</span> <span class="nb">all</span> <span class="p">)</span> <span class="o">+</span> <span class="n">vY</span><span class="p">(</span> <span class="nb">all</span> <span class="p">);</span>
                           <span class="p">}</span>
                         <span class="p">);</span>
</pre></div>
</div>
<p>This version of the kernel can be run on a CPU or GPU depending on the run time
chosen value of the variable <code class="docutils literal notranslate"><span class="pre">cpu_or_gpu</span></code>. When compiled, the code will
generate versions of the kernel for a CPU and an CUDA GPU based on the
parameters in the <code class="docutils literal notranslate"><span class="pre">pol_t</span></code> loop policy. The CPU version will be the same
as the version described earlier. The GPU version is essentially the same
but will run in a GPU kernel. Note that there is only one template argument
passed to the register when <code class="docutils literal notranslate"><span class="pre">vec_t</span></code> is defined.
<code class="docutils literal notranslate"><span class="pre">RAJA::expt::VectorRegister&lt;double&gt;</span></code> uses defaults for the register policy,
based on the system hardware, and number of data elements of type double that
will fit in a register.</p>
</section>
</section>
<section id="tensor-register">
<h2>Tensor Register<a class="headerlink" href="#tensor-register" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">RAJA::expt::TensorRegister&lt;</span> <span class="pre">&gt;</span></code> is a class template that provides a
higher-level interface on top of <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code>.
<code class="docutils literal notranslate"><span class="pre">RAJA::expt::TensorRegister&lt;</span> <span class="pre">&gt;</span></code> wraps one or more
<code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register&lt;</span> <span class="pre">&gt;</span></code> objects to create a tensor-like object.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As with <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code>, we don’t recommend using
<code class="docutils literal notranslate"><span class="pre">RAJA::expt::TensorRegister</span></code> directly. Rather, we recommend using
higher-level abstraction types that RAJA provides and which are
described below.</p>
</div>
</section>
<section id="matrix-registers">
<h2>Matrix Registers<a class="headerlink" href="#matrix-registers" title="Permalink to this headline">¶</a></h2>
<p>RAJA provides <code class="docutils literal notranslate"><span class="pre">RAJA::expt::TensorRegister</span></code> type aliases to support
matrices of arbitrary size and shape. These are:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">RAJA::expt::SquareMatrixRegister&lt;T,</span> <span class="pre">LAYOUT,</span> <span class="pre">REGISTER_POLICY&gt;</span></code> which
abstracts operations on an N x N square matrix.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RAJA::expt::RectMatrixRegister&lt;T,</span> <span class="pre">LAYOUT,</span> <span class="pre">ROWS,</span> <span class="pre">COLS,</span> <span class="pre">REGISTER_POLICY&gt;</span></code>
which abstracts operations on an N x M rectangular matrix.</p></li>
</ul>
</div></blockquote>
<p>Matrices are implemented using one or more <code class="docutils literal notranslate"><span class="pre">RAJA::expt::Register</span></code>
objects. Data layout can be row-major or column major. Matrices are intended
to be used with <code class="docutils literal notranslate"><span class="pre">RAJA::View</span></code> and <code class="docutils literal notranslate"><span class="pre">RAJA::expt::TensorIndex</span></code> objects,
similar to what was shown above in the <code class="docutils literal notranslate"><span class="pre">RAJA::expt::VectorRegister</span></code> example.</p>
<p>Matrix operations support matrix-matrix, matrix-vector, vector-matrix
multiplication, and transpose operations. Rows or columns can be represented
with one or more registers, or a power-of-two fraction of a single register.
This is important for GPU warp/wavefront registers, which are 32-wide for
CUDA and 64-wide for HIP.</p>
<p>Here is a code example that performs the matrix-analogue of the
vector DAXPY operation using square matrices:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Define</span> <span class="n">matrix</span> <span class="n">size</span> <span class="ow">and</span> <span class="n">data</span> <span class="n">used</span> <span class="ow">in</span> <span class="n">kernel</span> <span class="p">(</span><span class="n">similar</span> <span class="n">to</span> <span class="n">before</span><span class="p">)</span>
<span class="nb">int</span> <span class="n">N</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="n">a</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="n">const</span> <span class="o">*</span><span class="n">X</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="n">const</span> <span class="o">*</span><span class="n">Y</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="n">double</span> <span class="o">*</span><span class="n">Z</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>

<span class="o">//</span> <span class="n">Define</span> <span class="n">matrix</span> <span class="n">register</span> <span class="ow">and</span> <span class="n">row</span><span class="o">/</span><span class="n">column</span> <span class="n">index</span> <span class="n">types</span>
<span class="n">using</span> <span class="n">mat_t</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">SquareMatrixRegister</span><span class="o">&lt;</span><span class="n">double</span><span class="p">,</span>
                                               <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">RowMajorLayout</span><span class="o">&gt;</span><span class="p">;</span>
<span class="n">using</span> <span class="n">row_t</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">RowIndex</span><span class="o">&lt;</span><span class="nb">int</span><span class="p">,</span> <span class="n">mat_t</span><span class="o">&gt;</span><span class="p">;</span>
<span class="n">using</span> <span class="n">col_t</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">ColIndex</span><span class="o">&lt;</span><span class="nb">int</span><span class="p">,</span> <span class="n">mat_t</span><span class="o">&gt;</span><span class="p">;</span>

<span class="o">//</span> <span class="n">Wrap</span> <span class="n">array</span> <span class="n">pointers</span> <span class="ow">in</span> <span class="n">RAJA</span> <span class="n">View</span> <span class="n">objects</span> <span class="p">(</span><span class="n">similar</span> <span class="n">to</span> <span class="n">before</span><span class="p">)</span>
<span class="n">auto</span> <span class="n">mX</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">make_view</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span> <span class="p">);</span>
<span class="n">auto</span> <span class="n">mY</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">make_view</span><span class="p">(</span> <span class="n">Y</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span> <span class="p">);</span>
<span class="n">auto</span> <span class="n">mZ</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">make_view</span><span class="p">(</span> <span class="n">Z</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span> <span class="p">);</span>

<span class="n">using</span> <span class="n">cpu_launch</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">seq_launch_t</span><span class="p">;</span>
<span class="n">using</span> <span class="n">gpu_launch</span> <span class="o">=</span> <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">cuda_launch_t</span><span class="o">&lt;</span><span class="n">false</span><span class="o">&gt;</span><span class="p">;</span> <span class="o">//</span> <span class="n">false</span> <span class="o">=&gt;</span> <span class="n">launch</span>
                                                     <span class="o">//</span> <span class="n">CUDA</span> <span class="n">kernel</span>
                                                     <span class="o">//</span> <span class="n">synchronously</span>
<span class="n">using</span> <span class="n">pol_t</span> <span class="o">=</span>
  <span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">LoopPolicy</span><span class="o">&lt;</span> <span class="n">cpu_launch</span><span class="p">,</span> <span class="n">gpu_launch</span> <span class="o">&gt;</span><span class="p">;</span>

<span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">ExecPlace</span> <span class="n">cpu_or_gpu</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>

<span class="n">RAJA</span><span class="p">::</span><span class="n">expt</span><span class="p">::</span><span class="n">launch</span><span class="o">&lt;</span><span class="n">pol_t</span><span class="o">&gt;</span><span class="p">(</span> <span class="n">cpu_or_gpu</span><span class="p">,</span> <span class="n">resources</span><span class="p">,</span>

    <span class="p">[</span><span class="o">=</span><span class="p">]</span> <span class="n">RAJA_HOST_DEVICE</span> <span class="p">(</span><span class="n">context</span> <span class="n">ctx</span><span class="p">)</span> <span class="p">{</span>
       <span class="n">auto</span> <span class="n">rows</span> <span class="o">=</span> <span class="n">row_t</span><span class="p">::</span><span class="nb">all</span><span class="p">();</span>
       <span class="n">auto</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">col_t</span><span class="p">::</span><span class="nb">all</span><span class="p">();</span>
       <span class="n">mZ</span><span class="p">(</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="p">)</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">mX</span><span class="p">(</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="p">)</span> <span class="o">+</span> <span class="n">mY</span><span class="p">(</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="p">);</span>
    <span class="p">}</span>
  <span class="p">);</span>
</pre></div>
</div>
<p>Conceptually, as well as implementation-wise, this is similar to the previous
vector example except the operations are on two-dimensional matrices. The
kernel code is easy to read, it is guaranteed to vectorize, and iterating
over the data is handled by RAJA view objects (register-width sized chunk,
plus postamble scalar operations), and it can run on a CPU or NVIDIA GPU. As
before, the <code class="docutils literal notranslate"><span class="pre">RAJA::View</span></code> arithmetic operation overloads insert the
appropriate vector instructions in the code.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="workgroup.html" class="btn btn-neutral float-left" title="WorkGroup" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="plugins.html" class="btn btn-neutral float-right" title="Plugins" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2022, Lawrence Livermore National Security, LLNS.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>